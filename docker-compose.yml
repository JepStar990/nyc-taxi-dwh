services:
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    ports: [ "9000:9000", "9001:9001" ]
    volumes: [ "minio-data:/data" ]

  mc:
    image: minio/mc:latest
    container_name: mc
    depends_on: [ minio ]
    entrypoint: [ "sh", "-c", "tail -f /dev/null" ]  # keep running so I can exec into it
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - ./data:/data:ro  # so mc can mirror the local samples/external

  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    depends_on:
      - postgres
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: >-
        -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
        -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore
        -Djavax.jdo.option.ConnectionUserName=hive
        -Djavax.jdo.option.ConnectionPassword=hive
    ports:
      - "9083:9083"
    volumes:
      - ./infra/hive/postgres.jar:/opt/hive/lib/postgres.jar:ro

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore
    ports: [ "5432:5432" ]
    volumes: [ "pg-data:/var/lib/postgresql/data" ]

  trino:
    build: ./infra/docker/images/trino
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - S3_ENDPOINT=http://minio:9000
    ports: [ "8080:8080" ]
    depends_on: [ minio, hive-metastore ]

  kafka:
    image: apache/kafka:3.7.2
    container_name: kafka
    depends_on: []
    environment:
      # KRaft single-node (combined broker+controller)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # dev-friendly replication factors for internal topics on single broker
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    ports:
      - "9094:9094"
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 >/dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 5

  spark:
    build: ./infra/docker/images/spark
    environment:
      - SPARK_MODE=master
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - S3_ENDPOINT=http://minio:9000
    ports: [ "4040:4040", "18080:18080" ]
    depends_on: [ minio, hive-metastore ]
    volumes:
      - ./:/workspace
    command: ["bash", "-lc", "tail -f /dev/null"]

  airflow:
    build: ./infra/docker/images/airflow
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
      # OpenLineage â†’ Marquez
      - OPENLINEAGE_URL=http://marquez:5000
      - OPENLINEAGE_NAMESPACE=nyc-taxi-dwh
      - OPENLINEAGE_DISABLED=false
      # S3/MinIO for Spark jobs launched from Airflow
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - S3_ENDPOINT=http://minio:9000
      # Optional Slack for DQ alerts (set your real webhook to enable)
      # - SLACK_WEBHOOK=https://hooks.slack.com/services/XXX/YYY/ZZZ
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=myroot

    ports: [ "8088:8080" ]
    depends_on: [ spark, trino, kafka, marquez ]
    volumes:
      - ./:/workspace

  superset:
    build: ./infra/docker/images/superset
    ports: [ "8089:8088" ]
    depends_on: [ trino ]

  marquez:
    image: marquezproject/marquez:latest
    environment:
      MARQUEZ_DB_HOST: postgres
    ports: [ "5000:5000", "3001:3001" ]
    depends_on: [ postgres ]

  prometheus:
    image: prom/prometheus
    volumes: [ "../monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml" ]
    ports: [ "9090:9090" ]

  grafana:
    image: grafana/grafana:latest
    ports: [ "3000:3000" ]
    depends_on: [ prometheus ]

  redis:
    image: redis:7-alpine
    ports: [ "6379:6379" ]
    command: ["redis-server","--appendonly","yes"]

  vault:
    image: hashicorp/vault:1.15
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: myroot
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
    cap_add:
      - IPC_LOCK
    ports: [ "8200:8200" ]

volumes:
  minio-data: {}
  pg-data: {}
  kafka-data: {}
